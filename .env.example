# RAG-based FAQ System Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# üîê SECURITY CONFIGURATION
# =============================================================================
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# =============================================================================
# üìä DATABASE & REDIS CONFIGURATION
# =============================================================================
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/rag_faq
REDIS_URL=redis://localhost:6379

# =============================================================================
# üìÅ FILE UPLOAD CONFIGURATION
# =============================================================================
UPLOAD_DIR=uploads
MAX_FILE_SIZE=10485760
ALLOWED_EXTENSIONS=.pdf,.txt

# =============================================================================
# ‚è±Ô∏è TIMEOUT SETTINGS
# =============================================================================
UPLOAD_TIMEOUT=600
PROCESSING_TIMEOUT=300
REQUEST_TIMEOUT=300

# =============================================================================
# ü§ñ AI & ML CONFIGURATION
# =============================================================================
FAISS_INDEX_PATH=models/faiss_index
EMBEDDING_MODEL=all-MiniLM-L6-v2
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# =============================================================================
# üéØ RAG SETTINGS
# =============================================================================
TOP_K_CHUNKS=5
MIN_SIMILARITY_THRESHOLD=0.1
MAX_CONTEXT_LENGTH=4000
ANSWER_MAX_LENGTH=1000

# =============================================================================
# üß† LLM CONFIGURATION
# =============================================================================
# Choose your LLM provider: "openai", "cohere", or "stubbed"
LLM_PROVIDER=stubbed

# OpenAI Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here

# Cohere Configuration (required if LLM_PROVIDER=cohere)
COHERE_API_KEY=your-cohere-api-key-here

# LLM Response Settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# =============================================================================
# ‚öôÔ∏è ADVANCED SETTINGS
# =============================================================================
CHUNK_MIN_SIZE=100
USE_SIMILARITY_FILTER=true
USE_QUESTION_CLASSIFICATION=true

# =============================================================================
# üåê FRONTEND CONFIGURATION
# =============================================================================
REACT_APP_API_URL=http://localhost:8000/api/v1

# =============================================================================
# üìù ENVIRONMENT-SPECIFIC CONFIGURATIONS
# =============================================================================

# Development Environment (uncomment to use)
# DATABASE_URL=postgresql+asyncpg://dev_user:dev_pass@localhost:5432/rag_faq_dev
# LLM_PROVIDER=stubbed
# CHUNK_SIZE=800
# CHUNK_OVERLAP=150
# TOP_K_CHUNKS=3
# MIN_SIMILARITY_THRESHOLD=0.3

# Production Environment (uncomment to use)
# DATABASE_URL=postgresql+asyncpg://prod_user:secure_pass@prod-db:5432/rag_faq_prod
# REDIS_URL=redis://prod-redis:6379
# SECRET_KEY=your-very-secure-production-secret-key
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your-production-openai-key
# CHUNK_SIZE=1200
# CHUNK_OVERLAP=300
# TOP_K_CHUNKS=7
# MIN_SIMILARITY_THRESHOLD=0.4

# Testing Environment (uncomment to use)
# DATABASE_URL=postgresql+asyncpg://test_user:test_pass@localhost:5432/rag_faq_test
# LLM_PROVIDER=stubbed
# CHUNK_SIZE=600
# CHUNK_OVERLAP=100
# TOP_K_CHUNKS=2

# =============================================================================
# üéØ FINE-TUNING RECOMMENDATIONS
# =============================================================================

# For Technical Documents (uncomment to use)
# CHUNK_SIZE=800
# CHUNK_OVERLAP=150
# TOP_K_CHUNKS=3
# MIN_SIMILARITY_THRESHOLD=0.4
# LLM_TEMPERATURE=0.3

# For General Documents (uncomment to use)
# CHUNK_SIZE=1200
# CHUNK_OVERLAP=300
# TOP_K_CHUNKS=7
# MIN_SIMILARITY_THRESHOLD=0.3
# LLM_TEMPERATURE=0.7

# For FAQ-style Content (uncomment to use)
# CHUNK_SIZE=600
# CHUNK_OVERLAP=100
# TOP_K_CHUNKS=2
# MIN_SIMILARITY_THRESHOLD=0.5
# LLM_TEMPERATURE=0.5

# =============================================================================
# üìã CONFIGURATION NOTES
# =============================================================================
# 
# üîë API Keys:
# - OpenAI: Get from https://platform.openai.com/api-keys
# - Cohere: Get from https://dashboard.cohere.ai/api-keys
# - Use "stubbed" provider for testing without API keys
#
# üéØ LLM Provider Selection:
# - "openai": Best quality, requires API key
# - "cohere": Good quality, requires API key  
# - "stubbed": Basic template-based answers, no API key needed
#
# üìä Performance Tuning:
# - Lower CHUNK_SIZE for precise answers
# - Higher CHUNK_SIZE for context-rich answers
# - Adjust TOP_K_CHUNKS based on question complexity
# - Fine-tune MIN_SIMILARITY_THRESHOLD for answer quality
#
# üîí Security Notes:
# - Change SECRET_KEY in production
# - Use strong passwords for database
# - Keep API keys secure and never commit to version control
#
# üöÄ Deployment:
# - Use environment-specific configurations
# - Set appropriate timeouts for your infrastructure
# - Monitor memory usage with large documents 